no-auth, single-user design implement locally with LangGraph + Ollama + Postgres + RAG + Web search.

What the app does

One endpoint /chat. Talk to it like:

“Make me a 2-week plan to learn LangGraph”

“Quiz me on decorators”

“Track my progress: I finished topic X”

“What changed recently in LangChain?”
It uses:

RAG for your saved notes/docs

Web search for “latest”

Postgres to store plan, progress, quiz wrong questions, flashcards

Agents
1) Router Agent (traffic controller)

Job: decide what the user wants and which agents to call.
Outputs a structured decision like:

intent = PLAN | EXPLAIN | QUIZ | LOG_PROGRESS | REVIEW | LATEST

needs_rag = true/false

needs_web = true/false

needs_db = true/false

2) Planner Agent

Job: generate study plan + tasks + milestones.

3) DB agent

Job: reads/writes to DB. Can update plan, plan items based on progress. 
in future can write questions with wrong quiz answers to retry it and delete if successfully was answered 

3) Tutor (RAG) Agent

Job: answer using your local knowledge base (notes/PDFs/markdown), acts as kb for quiz on related topics
When confident, cite source filenames (even without perfect citations).

4) Quiz Agent

Job: generate questions, evaluate answers, and store mistakes/weak areas.
Supports modes: quick quiz (5 Q), interview drill.

5) Research Agent (Web)

Job: web search and summarize “what’s new / best practices / changes”
Then store useful findings as “materials” in DB (optional, not implemented for now).

Postgres schema (minimal)

sessions(session_id, started_at)

messages(id, session_id, role, content, created_at)

topics(topic_id, name, tags)

study_plan(plan_id, title, created_at)

plan_items(item_id, plan_id, topic_id, title, status, due_date, notes)

quiz_attempts(attempt_id, topic_id, question, user_answer, score, feedback, created_at)

flashcards(card_id, topic_id, front, back, last_seen, ease_factor, next_review_at)



RAG knowledge base (keep it simple)

Folder like:

kb/
  langchain.md
  langgraph.md
  python_interview.md
  links.md


Ingestion pipeline:

chunk files → embed → store vectors using ChromaDB

LangGraph orchestration (simple flow)

Graph nodes:

router

optional retrieve_context (RAG)

optional web_search

optional db

specialist_agent (planner/tutor/quiz/research)

final_response

Key rule: only one specialist agent per turn unless needed.

Example conversation flows
A) “Make me a plan”

Router → Planner → DB write → response (plan + next 3 actions)

B) “Explain X”

Router (EXPLAIN) → RAG retrieve → Tutor → response

C) “Quiz me”

Router (QUIZ) → RAG retrieve for related topics → Quiz Agent → DB write attempt → response

D) “What’s new in LangChain?”

Router (LATEST) → Web agent → optional save summary to DB → response

E) “I finished topic X”

Router (LOG_PROGRESS) → DB update → response (congrats + next step)

MVP scope (buildable fast)

- one FastAPI endpoint
- one LangGraph graph
- Postgres (messages, plan_items, quiz_attempts)
- RAG over local markdown
- basic web search tool
- Ollama local model
